\documentclass[main]{subfiles}

\begin{document}

\tableofcontents
\newpage

\section{Vector spaces}

\begin{definition}
$C\subseteq V$ is \textbf{convex}\index{Convex set} if $tC+(1-t)C\subseteq C$ for $0\leq t\leq1$. $C$ is \textbf{strictly convex}\index{Strictly convex set} if $tC+(1-t)C\subsetneqq C$ for $0< t<1$
\end{definition}

\begin{definition}
$V$ is a vector space of dimension $n$, a $q$ \textbf{flag}\index{Flag} is
\[0=V_0\subsetneq V_1\subsetneq\cdots\subsetneq V_q=V\]
A complete flag is an $n$ flag
\end{definition}

\begin{definition}
$V$ is an $n$ dimensional $\mathbb F$-vector, $\mathcal V=\{v_1,\cdots, v_n\}$ is a basis of $V$, $\{e_1,\cdots,e_n\}$ is the standard basis of $\mathbb F^n$, $V\to\mathbb F^n,v_i\mapsto e_i$ is an isomorphism, the matrix of $\phi\in\End(V)$ with respect to $\mathcal V$ is
\[A=
\begin{bmatrix}
a_{11}&\cdots&a_{1n} \\
\vdots&\ddots&\vdots \\
a_{n1}&\cdots&a_{nn}
\end{bmatrix}
\]
Such that $\phi(\mathcal V)=\mathcal VA$. If $v=\mathcal Vc$, then $\phi(v)=\mathcal VAc$
\end{definition}



\section{Matrices}

\begin{definition}
$I,J\subseteq\{1,\cdots,n\}$, the \textit{submatrix}\index{Submatrix} $A_{IJ}$ of $A$ is the matrix with entries $\{a_{ij}|i\in I,j\in J\}$. The \textit{principal submatrix}\index{principal submatrix} are matrices $A_{II}$
\end{definition}

\begin{definition}
$E_{ij}$ is the matrix with $1$ on the $(i,j)$-th entry and otherwise zeros, then $E_{ij}E_{kl}=\delta_{jk}E_{il}$ \par
Elementary matrices are single row operations, i.e.
\[e_{ij}(r)=\begin{pmatrix}
1&&&& \\
&\ddots&&r& \\
&&\ddots&& \\
&&&\ddots& \\
&&&&1
\end{pmatrix}\]
with $r$ on the $(i,j)$-th entry
\[s_{ij}=\begin{pmatrix}
1&&&&&& \\
&\ddots&&&&& \\
&&0&&1&& \\
&&&\ddots&&& \\
&&1&&0&& \\
&&&&&\ddots& \\
&&&&&&1
\end{pmatrix}\]
and
\[d_i(r)=\begin{pmatrix}
1&&&& \\
&\ddots&&& \\
&&r&& \\
&&&\ddots& \\
&&&&1
\end{pmatrix}\]
We have $e_{ij}(-r)=e_{ij}(r)^{-1}$ and
\begin{align*}
e_{ij}(r)e_{ij}(s)&=e_{ij}(r+s) \\
[e_{ij}(r),e_{kl}(s)]&=I+rs\delta_{jk}E_{il}-sr\delta_{li}E_{kj}+\delta_{jk}\delta_{li}(srsE_{kl}-rsrE_{ij})+rsrs\delta_{jk}\delta_{li}E_{il} \\
&=\begin{cases}
I&i\neq l,j\neq k \\
e_{il}(rs) &i=l,j\neq k \\
e_{kj}(-sr) &i\neq l,j=k \\
* &i=l,j=k
\end{cases}
\end{align*}
Steinberg relations
\end{definition}

\begin{definition}
$E(n,R)\subseteq SL(n,G)$ is the subgroup generated by elementary matrices of determinant $1$. $E(R)=\bigcup E(n,R)$
\end{definition}

\begin{lemma}
$SL(n,F)=E(n,F)$
\end{lemma}

\begin{lemma}\label{E(n,R) is perfect}
$[E(n,R),E(n,R)]=E(n,R)$ if $n\geq3$
\end{lemma}

\begin{proof}
For distinct $i,j,k$, $e_{ij}(r)=[e_{ik}(r),e_{kj}(1)]$
\end{proof}

\begin{theorem}[Whitehead's lemma]\label{Whitehead's lemma}
$[GL(R),GL(R)]=E(R)$, hence $K_1(R)=GL(R)/E(R)$
\end{theorem}

\begin{proof}
Since
\[e_{12}(1)e_{21}(-1)e_{12}(1)=\begin{pmatrix}
0&1 \\
-1&0
\end{pmatrix}\]
and
\[\begin{pmatrix}
g&\\
&g^{-1}
\end{pmatrix}=\begin{pmatrix}
1&g\\
&1
\end{pmatrix}\begin{pmatrix}
1&\\
-g^{-1}&1
\end{pmatrix}\begin{pmatrix}
1&g\\
&1
\end{pmatrix}\begin{pmatrix}
&-1\\
1&
\end{pmatrix}\]
We know
\[[g,h]=\begin{pmatrix}
g&\\
&g^{-1}
\end{pmatrix}
\begin{pmatrix}
h&\\
&h^{-1}
\end{pmatrix}
\begin{pmatrix}
(hg)^{-1}&\\
&hg
\end{pmatrix}\in E(R)\]
\end{proof}

\begin{definition}
The \textit{Kronecker product}\index{Kronecker product} of matrices
\[A=\begin{pmatrix}
a_{11} &\cdots &a_{1n} \\
\vdots & \ddots &\vdots \\
a_{m1} &\cdots &a_{mn}
\end{pmatrix},\,B=\begin{pmatrix}
b_{11} &\cdots &b_{1p} \\
\vdots & \ddots &\vdots \\
a_{np} &\cdots &b_{np}
\end{pmatrix}\]
is
\[A\otimes B=
\begin{pmatrix}
a_{11}B &\cdots &a_{1n}B \\
\vdots & \ddots &\vdots \\
a_{m1}B &\cdots &a_{mn}B
\end{pmatrix}\]
\end{definition}

\begin{definition}
$\tr(A^*B)$ defines the \textit{Frobenius inner product}\index{Frobenius inner product} over $M(n,\mathbb C)$
\end{definition}



\section{Eigenspace decomposition}

\begin{proposition}
$T\in\mathrm{Hom}_{\mathbb F}(V,V)$ is a linear operator, and $V=\displaystyle\bigoplus_{i}V_i$, where $V_i$ are $T$ invariant spaces, denote $T|_{V_i}$ as $T-i$, then $ch_T(t)=\displaystyle\prod_{i}ch_{T_i}(t)$, and $m_T(t)=\underset{i}{lcm}\,\, m_{T_i}(t)$
\end{proposition}

\begin{definition}
$T\in\mathrm{Hom}_{\mathbb F}(V,V)$. $\lambda\in F$ is an \textbf{eigenvalue} if $Tv=\lambda v$ has nontrivial solution, $v\in V$ is a \textbf{generalized eigenvector}\index{generalized eigenvector} of rank $m$ of $T$ corresponding to eigenvalue $\lambda$ if $(T-\lambda1_V)^mv=0,(T-\lambda1_V)^{m-1}v\neq0$ for some $m\geq1$, and let $V_\lambda$ be the subspace of all such generalized eigenvectors, called \textbf{generalized eigenspace}\index{Generalized eigenspace}, notice if $V$ is of finite dimensional, then $V_\lambda=\ker(T-\lambda1_V)^m$ for some $m$ with $m$ being smallest, suppose $\dim V_\lambda=d$, then the characteristic polynomial of $T|_{V_\lambda}$ is $(t-\lambda)^d$, and the minimal polynomial of $T|_{V_\lambda}$ is $(t-\lambda)^m$
\end{definition}

\begin{proposition}\label{Generalized eigenspace decomposition}
$\overline F=F$, finitely dimensional $F$ vector space $V$ can be decomposed into the direct sum of generalized eigenspaces $V=\displaystyle\bigoplus_{\lambda}V_\lambda$
\end{proposition}

\begin{definition}
$T\in\mathrm{Hom}_{\mathbb F}(V,V)$ give $V$ an $F[x]$ module with $x\cdot v=Tv$, $W\leq V$ be a subspace, $W$ is called $T$ \textbf{invariant}\index{Invariant subspace} if $TW\subseteq W$, or rather $W$ is an $F[x]$ submodule
\end{definition}

\begin{definition}
An linear operator $T\in\mathrm{Hom}_{\mathbb F}(V,V)$ is called \textbf{semisimple}\index{Semisimple linear operator} if $V$ is a semisimple $\mathbb F[x]$ submodule
\end{definition}

\begin{proposition}
Let $T\in\mathrm{Hom}_{\mathbb F}(V,V)$ be a linear operator with $\overline{\mathbb F}=\mathbb F$, then $T$ is semisimple $\Leftrightarrow$ $T$ is diagonalizable
\end{proposition}

\begin{proof}
Since $\overline{\mathbb F}=\mathbb F$ and $T$ is semisimple, $V$ can be decomposed as a direct sum of eigenspaces of $T$, thus $T$ is diagonalizable, conversely, if $T$ is diagonalizable, and $TW\subseteq W$, let $V_\lambda$ be the eigenspaces of $T$, denote $W_\lambda=W\cap V_\lambda$, and $W'=\bigoplus_{\lambda}W_\lambda'$, since $T|_{V_\lambda}=\lambda1_{V_\lambda}$, we can find $W_\lambda'\leq V_\lambda$ such that $V_\lambda=W_\lambda\oplus W_\lambda'$, and of course $TW_\lambda'\subseteq W_\lambda'$ which implies $TW'\subseteq W'$, then we have $V=\displaystyle\bigoplus_{\lambda}V_\lambda=\bigoplus_{\lambda}W_\lambda\oplus W_\lambda'=\bigoplus_{\lambda}W_\lambda\bigoplus\bigoplus_{\lambda}W_\lambda'=W\oplus W'$
\end{proof}

\begin{definition}
An linear operator $T\in\mathrm{Hom}_{\mathbb F}(V,V)$ is called nilpotent if $T^k=0$ for some $k$, $T$ is called unipotent if $T-1_V$ is nilpotent
\end{definition}

\begin{definition}[Jordan-Chevalley decomposition]\label{Jordan-Chevalley decomposition}\index{Jordan-Chevalley decomposition}
\textbf{Jordan-Chevalley decomposition} of a linear operator $T\in\mathrm{Hom}_{\mathbb F}(V,V)$  is $T=T_s+T_n$, where $T_s$ is semisimple, $T_n$ is nilpotent and $[T_s,T_n]=0$
\end{definition}

\begin{theorem}\label{Existence of Jordan-Chevalley decomposition}
If $V$ is a finite dimensional $\mathbb F$ vector space with $\mathbb F$ being a perfect field, and $T\in\mathrm{Hom}_{\mathbb F}(V,V)$ is a linear operator, then Jordan-Chevalley decomposition always exist, additionally, there exist polynomials $p(t),q(t)$ with no constant terms and $T_s=p(T),T_n=q(T)$, moreover, the decomposition is unique
\end{theorem}

\begin{proof}
First consider $\overline{\mathbb F}=\mathbb F$, by Proposition \ref{Generalized eigenspace decomposition}, $V$ can be decomposed into the direct sum of generalized eigenspaces $V=\displaystyle\bigoplus_{i}V_{\lambda_i}$, where $V_{\lambda_i}=\ker(T-\lambda_i1_V)^{m_i}$ with being $m_i$ being the least and $\dim V_{\lambda_i}=d_i$, define $T_s\in\mathrm{Hom}_{\mathbb F}(V,V)$ such that $T_s|_{V_{\lambda_i}}=\lambda_i1_{V_{\lambda_i}}$ and $T_n=T-T_s$, thus $T_s$ is diagonalizable(semisimple), $T_n$ is nilpotent, $ch_T(t)=\displaystyle\prod_{i}(t-\lambda_i)^{d_i}$, by Theorem \ref{Chinese remainder theorem}, there exists polynomial $p(t)$ such that $p(t)\equiv0\mod t$, $p(t)\equiv\lambda_i\mod(t-\lambda_i)^{d_i}$, and let $q(t)=t-p(t)$, then $p,q$ doesn't have constant terms and $T_s=p(T),T_n=q(T)$. For uniqueness, suppose $T=T_s+T_n=T_s'+T_n'$ are two such decompositions, then $T_s-T_s'=T_n'-T_n$ will be nilpotent which implies $T_s-T_s'=0$
\end{proof}



\section{Bilinear form}

\begin{definition}
A \textit{symplectic form}\index{Symplectic form} $\omega$ is bilinear form such that $\omega(u,v)=X^TJY$, here $J=\begin{pmatrix}
&-I \\
I&
\end{pmatrix}$, in other words, there are $u_1,\cdots,u_n,v_1,\cdots,v_n$ such that $\omega(u_i,v_j)=-\omega(v_j,u_i)=\delta_{ij}$, $\omega(u_i,u_j)=\omega(v_i,v_j)=0$
\end{definition}

\begin{remark}
$\omega(x\oplus\xi,y\oplus\eta)=\eta(x)-\xi(y)$ on $V\oplus V^*$ is a symplectic form. Conversely, such a $V$ is called a Lagrangian subspace, a polarization
\end{remark}

\end{document}